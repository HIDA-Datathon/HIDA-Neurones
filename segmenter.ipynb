{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding water with neural nets\n",
    "\n",
    "HIDA - Datathon 2020 Solution by\n",
    "\n",
    "**Team neutrons_net**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "import numpy as np\n",
    "from PIL import Image, ImageFont, ImageDraw \n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "import pandas as pd\n",
    "import sys\n",
    "import random\n",
    "sys.path.insert(0,'.')\n",
    "import colorsys\n",
    "\n",
    "from src.utils import keras_losses as loss\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random colors:\n",
    "def random_colors(N, bright=True):\n",
    "    \"\"\"\n",
    "    Generate random colors.\n",
    "    To get visually distinct colors, generate them in HSV space then\n",
    "    convert to RGB.\n",
    "    \"\"\"\n",
    "    brightness = 1.0 if bright else 0.7\n",
    "    hsv = [(i / N, 1, brightness) for i in range(N)]\n",
    "    colors = list(map(lambda c: colorsys.hsv_to_rgb(*c), hsv))\n",
    "    random.shuffle(colors)\n",
    "    return colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(path='notebooks/models/unet2_weights.h5'):\n",
    "    model = loss.make_model(image_size=(224, 224))\n",
    "    #model.compile(loss=loss.BCE_dice, optimizer='sgd', metrics=['accuracy'])\n",
    "    model.load_weights(path)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\simon\\.julia\\conda\\3\\envs\\hidaneurones\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "model = setup_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(input_img, output_img,feature_legend_path='notebooks/models/features_legend.csv', seed = 42):\n",
    "    # load original image and image with annotations\n",
    "    original_image = input_img\n",
    "    #image_annotations = Image.open(annotated_image_path).convert('RGB')\n",
    "    image_annotations = Image.fromarray(output_img)\n",
    "    # set annotated image to semi-transparent\n",
    "    image_annotations.putalpha(alpha = 128)\n",
    "    \n",
    "    # create nice looking colors\n",
    "    random.seed(seed)\n",
    "    colors = random_colors(20)\n",
    "    \n",
    "    # transform image so one can work with it\n",
    "    image_transformed = np.array(image_annotations)\n",
    "\n",
    "    height = np.array(image_annotations).shape[0]\n",
    "    width = np.array(image_annotations).shape[1]\n",
    "\n",
    "    image_transformed = image_transformed.reshape(height*width, 4)\n",
    "\n",
    "    # Make black pixels transparent:\n",
    "    image_transformed = [[0, 0, 0, 0]  if v == [0, 0, 0, 128] else v for v in image_transformed.tolist()]\n",
    "\n",
    "    # Resetting RGB ID's to nice colors:\n",
    "    for i in range(1,21) :\n",
    "        r = colors\n",
    "        image_transformed = [[colors[i][0]*255, colors[i][1]*255, colors[i][2]*255, 128]  if v == [i, i, i, 128] else v for v in image_transformed]\n",
    "\n",
    "\n",
    "    #Reshape and make it Image type again\n",
    "    image_transformed = np.array(image_transformed, dtype = 'uint8')\n",
    "    image_transformed = image_transformed.reshape(height, width, 4)\n",
    "    \n",
    "    #Put original image in the background and paste annotations over it\n",
    "\n",
    "    img = Image.fromarray(image_transformed)\n",
    "    background = original_image\n",
    "    background.putalpha(alpha = 255)\n",
    "    background.paste(img, (0, 0), img)\n",
    "    \n",
    "    output_image_without_writing = background\n",
    "    \n",
    "    # Calculate percentages\n",
    "    rgb_ids = pd.read_csv(feature_legend_path)\n",
    "    \n",
    "    image_annotations = output_img\n",
    "    image_annotations = np.array(image_annotations)\n",
    "    height = np.array(image_annotations).shape[0]\n",
    "    width = np.array(image_annotations).shape[1]\n",
    "\n",
    "    image_for_counting = image_annotations.reshape(height*width, 3).tolist()\n",
    "    \n",
    "    rgb_ids['percentage'] = 0\n",
    "    for i in range(1, 21):\n",
    "        rgb_ids['percentage'][rgb_ids['id_rgb'] == i] = (image_for_counting.count([i, i, i])/(height*width))*100\n",
    "    \n",
    "    # Write percentages on image\n",
    "    dataframe_for_writing = rgb_ids[rgb_ids['percentage'] > 0]\n",
    "    \n",
    "    #Select Arial as font\n",
    "    title_font = ImageFont.truetype(r'notebooks/models/Roboto/Roboto-Regular.ttf', 20)\n",
    "\n",
    "    for i in range(0, dataframe_for_writing.shape[0]):\n",
    "        title_text = f\"{dataframe_for_writing[' label'].iloc[i]}: {round(dataframe_for_writing['percentage'].iloc[i], 2)}%\"\n",
    "\n",
    "        image_editable = ImageDraw.Draw(output_image_without_writing)\n",
    "        image_editable.text((15,15 + i*25), title_text, (0, 0, 0), font=title_font)\n",
    "        \n",
    "    output_image = output_image_without_writing\n",
    "    \n",
    "    return output_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_inference(img, model):\n",
    "    img = np.array(img)[None, :, :, :]\n",
    "    img = tf.keras.applications.mobilenet_v2.preprocess_input(img)\n",
    "    pre = model.predict(img)\n",
    "\n",
    "    pre = np.argmax(pre, axis=-1).squeeze()\n",
    "    \n",
    "    return pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_click_classify(change):\n",
    "    img = Image.open(io.BytesIO(btn_upload.data[-1]))\n",
    "    img = img.resize((224, 224))\n",
    "    pred = img_inference(img, model)\n",
    "\n",
    "    pred = np.uint8((np.stack([pred, pred, pred], axis=-1)))\n",
    "\n",
    "    pred = visualize(img, pred)\n",
    "    with image_pl: \n",
    "        display(img)\n",
    "\n",
    "    with prediction_pl: \n",
    "        display(pred)\n",
    "\n",
    "\n",
    "btn_upload = widgets.FileUpload()\n",
    "image_pl = widgets.Output()\n",
    "prediction_pl = widgets.Output()\n",
    "lbl_pred = widgets.Label()\n",
    "lbl_pred.value = \"Select an image for Classification!\"\n",
    "btn_run = widgets.Button(description='Classify')\n",
    "btn_run.on_click(on_click_classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1823dfd7a6a4af5b132b6d6dc2c9c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(FileUpload(value={}, description='Upload'), Button(description='Classify', style=ButtonStyle())â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.VBox([btn_upload, btn_run])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56d8b55bda1540b1bd8c61d8abaa167e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Output(), Output()))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widgets.HBox([image_pl, prediction_pl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python hidaneurones",
   "language": "python",
   "name": "hidaneurones"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
