{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from glob import glob\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/home/simon/GithubRepros/HIDA-Neurones/data/HIDA-ufz_image_challenge/photos_annotated'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, datapath='.././data/HIDA-ufz_image_challenge/photos_annotated', \n",
    "                       image_size=(224, 224), batch_size=1, shuffle=False, step='train',\n",
    "                nb_labels=20, augmentation=None):\n",
    "        \"\"\"Data generator for validation and training.\n",
    "        Args:\n",
    "            image_csv (pd.DataFrame): Dataframe with absolute path to images in\n",
    "                                      \"Filename\", and bounding boxe locations.\n",
    "            image_size (tuple, optional): Target size of images. Defaults to (224, 224).\n",
    "            batch_size (int, optional): Batch size. Defaults to 1.\n",
    "            shuffle (bool, optional): Whether to shuffle before creating batches. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.datapath = datapath\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.image_size = image_size\n",
    "        self.image_list = sorted(glob(os.path.join(self.datapath, '*.jpg')))\n",
    "        self.label_list = sorted(glob(os.path.join(self.datapath, '*.png')))\n",
    "        self.step = step\n",
    "        self.nb_labels = nb_labels\n",
    "        self.augmentation=augmentation\n",
    "        \n",
    "        if len(self.image_list) != len(self.label_list):\n",
    "            warnings.warn('Warning, data length is different!')\n",
    "            \n",
    "        self.data_size = len(self.image_list)\n",
    "        \n",
    "        if self.step != 'train' and self.shuffle:\n",
    "            warning.warn('Warning, shuffle is True, but it is not a training generator!')\n",
    "            \n",
    "        \n",
    "        if self.step == 'train':\n",
    "            self.image_list = self.image_list[: int(0.8 * self.data_size)]\n",
    "            self.label_list = self.label_list[: int(0.8 * self.data_size)]\n",
    "        elif self.step == 'valid':\n",
    "            self.image_list = self.image_list[int(0.8 * self.data_size):int(0.9 * self.data_size)]\n",
    "            self.label_list = self.label_list[int(0.8 * self.data_size):int(0.9 * self.data_size)]\n",
    "        elif self.step == 'test':\n",
    "            self.image_list = self.image_list[int(0.9 * self.data_size):]\n",
    "            self.label_list = self.label_list[int(0.9 * self.data_size):]\n",
    "            \n",
    "            \n",
    "        self.set_size = len(self.image_list)\n",
    "        \n",
    "        self.images, self.labels = self.load_data()\n",
    "        \n",
    "        \n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def load_data(self):\n",
    "\n",
    "        image_array = []\n",
    "        label_array = []\n",
    "        \n",
    "        \n",
    "        for img, label in tqdm(zip(self.image_list, self.label_list), total=self.set_size, desc='Loading images'):\n",
    "            if self._assert_images(img, label):\n",
    "                image_array.append(np.array(Image.open(img).resize(self.image_size)))\n",
    "                \n",
    "                label = np.array(Image.open(label).resize(self.image_size))\n",
    "                if len(label.shape) == 2:\n",
    "                    label_array.append(label)\n",
    "                elif len(label.shape) == 3:\n",
    "                    label_array.append(label[:, :, 0])\n",
    "                else:\n",
    "                    print(\"Error\")\n",
    "    \n",
    "        return np.array(image_array), np.array(label_array)\n",
    "        \n",
    "\n",
    "    def _assert_images(self, im_path, label_path):\n",
    "        \n",
    "        if im_path[0].split('/')[-1].split('.')[0] == label_path[0].split('/')[-1].split('.')[0]:\n",
    "            return True\n",
    "        else:\n",
    "            warnings.warn(\"Warning, data not matching!\")\n",
    "            return False\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        # Calculate the lenght of the generator (i.e. number of batches in epoch)\n",
    "        return int(np.floor(self.set_size / self.batch_size))\n",
    "\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # Indices = number of files in there (even if it's df)\n",
    "        self.indexes = np.arange(self.set_size)\n",
    "\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Create indices (shuffled)\n",
    "        indexes = self.indexes[index * self.batch_size: (index + 1) * self.batch_size]\n",
    "\n",
    "        X, y = self.__data_generation(indexes)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def __data_generation(self, indexes):\n",
    "        X, y = [], []\n",
    "\n",
    "        # Generate data\n",
    "        for idx in indexes:\n",
    "            # Load image, save dimensions and resize:\n",
    "            img = self.images[idx]\n",
    "            mask = self.labels[idx]\n",
    "            \n",
    "            \n",
    "            if self.augmentation:\n",
    "                augmented = self.augmentation(self.image_size)(image=img, mask=mask)\n",
    "                \n",
    "                image_augm = augmented['image']\n",
    "                mask_augm = augmented['mask'].reshape(*self.image_size, self.nb_labels)\n",
    "                \n",
    "                # divide by 255 to normalize images from 0 to 1\n",
    "                img = image_augm/255\n",
    "                mask = mask_augm\n",
    "            \n",
    "            X.append(img)\n",
    "            y.append(mask)\n",
    "\n",
    "        return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "179a2eaf3bcd4d8f80fadef9d4028677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Loading images'), FloatProgress(value=0.0, max=663.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train = DataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python HIDA",
   "language": "python",
   "name": "hida"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
